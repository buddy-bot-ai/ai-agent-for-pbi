{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7e83f7-dd67-4976-8e7a-db40617b8582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required imports for the Power BI automation script\n",
    "import os\n",
    "import cv2\n",
    "import base64\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import pyautogui\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from anthropic import Anthropic\n",
    "import mss\n",
    "import easyocr\n",
    "import warnings\n",
    "import itertools\n",
    "import io\n",
    "\n",
    "# Configuration and setup\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pyautogui.FAILSAFE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45484914-668e-4373-9774-d70fb2c7a4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Anthropic client with API key from environment\n",
    "ANTHROPIC_CLIENT = Anthropic(api_key=os.getenv(\"ANTHROPIC_API_KEY\"))\n",
    "MODEL_NAME = \"claude-3-7-sonnet-20250219\"\n",
    "\n",
    "# Constants for icon folder and screen resolution\n",
    "ICONS_DIRECTORY = \"icons\"\n",
    "SCREEN_WIDTH = 1920\n",
    "SCREEN_HEIGHT = 1080\n",
    "MATCH_MATCH_THRESHOLD = 0.9\n",
    "\n",
    "# Initialize Easyperform_ocr reader for English text detection\n",
    "OCR_READER = easyocr.Reader(['en'], gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d89472e-c93b-4160-8481-a417cd0b188a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_icons(icons_folder=\"icons\", MATCH_THRESHOLD=0.9):\n",
    "    \"\"\"\n",
    "    Match all icons in the icons_folder against a screenshot and return their center positions.\n",
    "    \n",
    "    Args:\n",
    "        icons_folder (str): Path to the folder containing icon images (default: \"icons\").\n",
    "        MATCH_THRESHOLD (float): Minimum correlation coefficient for a match (default: 0.8).\n",
    "    \n",
    "    Returns:\n",
    "        list: List of dictionaries in the format {\"icon_name\": str, \"x\": int, \"y\": int}.\n",
    "    \"\"\"\n",
    "    # Step 1: Take screenshot\n",
    "    with mss.mss() as sct:\n",
    "        screenshot = sct.grab(sct.monitors[1])\n",
    "        img = np.array(screenshot)\n",
    "        main_image = cv2.cvtColor(img, cv2.COLOR_BGRA2BGR)\n",
    "\n",
    "    if main_image is None:\n",
    "        raise FileNotFoundError(\"Could not load screenshot.\")\n",
    "\n",
    "    main_gray = cv2.cvtColor(main_image, cv2.COLOR_BGR2GRAY)\n",
    "    matched_icons = []\n",
    "\n",
    "    # Step 3: Iterate through all files in the icons folder\n",
    "    for icon_file in os.listdir(icons_folder):\n",
    "        if not icon_file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
    "            continue\n",
    "\n",
    "        icon_name = os.path.splitext(icon_file)[0]\n",
    "        icon_path = os.path.join(icons_folder, icon_file)\n",
    "\n",
    "        template = cv2.imread(icon_path)\n",
    "        if template is None:\n",
    "            print(f\"Warning: Could not load icon: {icon_path}\")\n",
    "            continue\n",
    "\n",
    "        template_gray = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)\n",
    "        t_height, t_width = template_gray.shape[:2]\n",
    "\n",
    "        res = cv2.matchTemplate(main_gray, template_gray, cv2.TM_CCOEFF_NORMED)\n",
    "        loc = np.where(res >= MATCH_THRESHOLD)\n",
    "\n",
    "        for pt in zip(*loc[::-1]):\n",
    "            center_x = int(pt[0] + t_width // 2)\n",
    "            center_y = int(pt[1] + t_height // 2)\n",
    "            matched_icons.append({\n",
    "                \"icon_name\": icon_name,\n",
    "                \"x\": center_x,\n",
    "                \"y\": center_y\n",
    "            })\n",
    "\n",
    "    return matched_icons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc32df14-542d-4d6f-82ce-bbd680b8a954",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_ocr():\n",
    "    \"\"\"\n",
    "    Extract text and icons from a screenshot with their positions.\n",
    "    \n",
    "    Returns:\n",
    "        str: Concatenated string of detected text and icons in format {text, x, y} and {icon_name, x, y}.\n",
    "    \"\"\"\n",
    "    detected_items = []\n",
    "\n",
    "    # Step 1: Take screenshot\n",
    "    with mss.mss() as sct:\n",
    "        screenshot = sct.grab(sct.monitors[1])\n",
    "        img = np.array(screenshot)\n",
    "        image = cv2.cvtColor(img, cv2.COLOR_BGRA2BGR)\n",
    "\n",
    "    # Run perform_ocr\n",
    "    results = OCR_READER.readtext(image, detail=1)\n",
    "\n",
    "    for bbox, detected_text, _ in results:\n",
    "        # Calculate center of bounding box\n",
    "        x_coords = [point[0] for point in bbox]\n",
    "        y_coords = [point[1] for point in bbox]\n",
    "        center_x = int(sum(x_coords) / len(x_coords))\n",
    "        center_y = int(sum(y_coords) / len(y_coords))\n",
    "\n",
    "        # Format as {text, x, y}\n",
    "        detected_items.append(f\"{{{detected_text}, {center_x}, {center_y}}}\")\n",
    "\n",
    "    icons = find_all_icons(icons_folder=\"icons\", MATCH_THRESHOLD=0.9)\n",
    "    results = ''.join(detected_items) + json.dumps(icons)\n",
    "\n",
    "    return results\n",
    "\n",
    "def find_and_click_item(item_name):\n",
    "    \"\"\"\n",
    "    Locate and click an item by its text using OCR.\n",
    "    \n",
    "    Args:\n",
    "        item_name (str): Text of the item to click.\n",
    "    \n",
    "    Returns:\n",
    "        str: Result message indicating success or failure.\n",
    "    \"\"\"\n",
    "    print(f\"Looking for: '{item_name}'\")\n",
    "\n",
    "    # Take screenshot\n",
    "    with mss.mss() as sct:\n",
    "        screenshot = sct.grab(sct.monitors[1])\n",
    "        img = np.array(screenshot)\n",
    "        image = cv2.cvtColor(img, cv2.COLOR_BGRA2BGR)\n",
    "\n",
    "    # Run perform_ocr\n",
    "    results = OCR_READER.readtext(image, detail=1)\n",
    "\n",
    "    perform_ocr_lines = []\n",
    "    for bbox, text, conf in results:\n",
    "        y_center = (bbox[0][1] + bbox[2][1]) / 2\n",
    "        cleaned_text = text.strip()\n",
    "        perform_ocr_lines.append({\n",
    "            'text': cleaned_text,\n",
    "            'bbox': bbox,\n",
    "            'y_center': y_center\n",
    "        })\n",
    "\n",
    "    item_name_lower = item_name.strip().lower()\n",
    "\n",
    "    # === Stage 1: Try individual match ===\n",
    "    for line in perform_ocr_lines:\n",
    "        if item_name_lower in line['text'].lower():\n",
    "            x_coords = [pt[0] for pt in line['bbox']]\n",
    "            y_coords = [pt[1] for pt in line['bbox']]\n",
    "            center_x = int(sum(x_coords) / len(x_coords))\n",
    "            center_y = int(sum(y_coords) / len(y_coords))\n",
    "\n",
    "            print(f\"\\n Found direct match:\\nText: '{line['text']}'\\nClicking at (x={center_x}, y={center_y})\")\n",
    "            pyautogui.moveTo(center_x, center_y, duration=2)\n",
    "            pyautogui.click(center_x, center_y, clicks=2, interval=0.25)\n",
    "            pyautogui.moveTo(SCREEN_WIDTH/2, SCREEN_HEIGHT/2) \n",
    "            return f\"Item '{item_name}' clicked at (x={center_x}, y={center_y})\"\n",
    "\n",
    "    # === Stage 2: Try combining nearby lines ===\n",
    "    for group_size in [2, 3]:\n",
    "        for combo in itertools.combinations(perform_ocr_lines, group_size):\n",
    "            y_positions = [line['y_center'] for line in combo]\n",
    "            if max(y_positions) - min(y_positions) > 40:\n",
    "                continue  # Skip if lines are too far apart vertically\n",
    "\n",
    "            combined_text = \" \".join(line['text'] for line in combo)\n",
    "            combined_bbox = []\n",
    "            for line in combo:\n",
    "                combined_bbox.extend(line['bbox'])\n",
    "\n",
    "            if item_name_lower in combined_text.lower():\n",
    "                x_coords = [pt[0] for pt in combined_bbox]\n",
    "                y_coords = [pt[1] for pt in combined_bbox]\n",
    "                center_x = int(sum(x_coords) / len(x_coords))\n",
    "                center_y = int(sum(y_coords) / len(y_coords))\n",
    "\n",
    "                print(f\"\\n Found combined match:\\nCombined Text: '{combined_text}'\\nClicking at (x={center_x}, y={center_y})\")\n",
    "                pyautogui.moveTo(center_x, center_y, duration=2)\n",
    "                pyautogui.click(center_x, center_y, clicks=2, interval=0.25)\n",
    "                pyautogui.moveTo(SCREEN_WIDTH/2, SCREEN_HEIGHT/2) \n",
    "                return f\"Item '{item_name}' clicked at (x={center_x}, y={center_y})\"\n",
    "\n",
    "    print(f\"\\n Item '{item_name}' not found\")\n",
    "    return f\"Item '{item_name}' not found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615b6455-c953-42d6-b7d1-1ebaaf551c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_and_click_icon(icon_name, MATCH_THRESHOLD=0.9):\n",
    "    \"\"\"\n",
    "    Locate and click an icon by matching it against a screenshot.\n",
    "    \n",
    "    Args:\n",
    "        icon_name (str): Name of the icon to click.\n",
    "        match_threshold (float): Minimum correlation coefficient for a match.\n",
    "    \n",
    "    Returns:\n",
    "        str: Result message indicating success or failure.\n",
    "    \"\"\"\n",
    "    # Take screenshot\n",
    "    with mss.mss() as sct:\n",
    "        screenshot = sct.grab(sct.monitors[1])\n",
    "        img = np.array(screenshot)\n",
    "        main_image = cv2.cvtColor(img, cv2.COLOR_BGRA2BGR)\n",
    "\n",
    "    icon_path = os.path.join(os.getcwd(), ICONS_DIRECTORY, icon_name + \".png\")\n",
    "\n",
    "    # Load template\n",
    "    template = cv2.imread(icon_path)\n",
    "\n",
    "    if main_image is None or template is None:\n",
    "        raise FileNotFoundError(\"Could not load screenshot or icon image.\")\n",
    "\n",
    "    # Convert to grayscal\n",
    "    main_gray = cv2.cvtColor(main_image, cv2.COLOR_BGR2GRAY)\n",
    "    template_gray = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Template matching\n",
    "    res = cv2.matchTemplate(main_gray, template_gray, cv2.TM_CCOEFF_NORMED)\n",
    "    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n",
    "\n",
    "    if max_val >= MATCH_THRESHOLD:\n",
    "        # Get dimensions of the template\n",
    "        t_height, t_width = template_gray.shape[:2]\n",
    "\n",
    "        # Calculate center coordinates\n",
    "        center_x = max_loc[0] + t_width // 2\n",
    "        center_y = max_loc[1] + t_height // 2\n",
    "        \n",
    "        print(f\"Found icon '{icon_name}' at (x={center_x}, y={center_y})\")\n",
    "        pyautogui.moveTo(center_x, center_y, duration=2)\n",
    "        pyautogui.click(center_x, center_y)\n",
    "        pyautogui.moveTo(SCREEN_WIDTH/2, SCREEN_HEIGHT/2) \n",
    "        return f\"Icon '{icon_name}' c/2licked at (x={center_x}, y={center_y})\"\n",
    "    else:\n",
    "        print(f\"Icon '{icon_name}' not found\")\n",
    "        return f\"Icon '{icon_name}' not found\"  # No match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d9e878-fcbb-4001-a3e1-64a591d12284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_pbi():\n",
    "    \"\"\"\n",
    "    Open Power BI Desktop application.\n",
    "    \n",
    "    Returns:\n",
    "        str: Confirmation message.\n",
    "    \"\"\"\n",
    "    pyautogui.hotkey(\"win\", \"s\") # Open Windows search\n",
    "    time.sleep(1)\n",
    "    pyautogui.typewrite(\"Power BI Desktop\")\n",
    "    time.sleep(1)\n",
    "    pyautogui.press(\"enter\")\n",
    "    time.sleep(5) # Wait for Power BI to open\n",
    "    return \"PowerBI is now open\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633d8c51-c729-478b-ad95-99ba3cd788ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"name\": \"open_pbi\",\n",
    "        \"description\": \"This tool is exclusively for opening the Power BI app and must not be used to open any other application.\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {},\n",
    "            \"required\": []\n",
    "         }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"find_and_click_item\",\n",
    "        \"description\": \"This tool is exclusively for clicking or double-clicking any item, including button, menu, and files, and must not be used for any other tasks.\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                 \"item_name\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The text of an item, including button, menu, and files, which needs to be clicked or double-clicked\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"item_name\"]\n",
    "         }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"find_and_click_icon\",\n",
    "        \"description\": \"This tool is exclusively for clicking or double-clicking any icon, including visualisations icons, chevron right, right arrow, rectangle, and checkmark icons, and must not be used for any other tasks.\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                 \"icon_name\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The name of an icon, including visualisations icons, which needs to be clicked or double-clicked. The icon names can be 'bar chart' , 'column chart' , 'chevron right' , 'right arrow', 'rectangle', or 'checkmark'\",\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"icon_name\"]\n",
    "         }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"perform_ocr\",\n",
    "        \"description\": \"This tool is exclusively for extracting and returning a string of all text and icons detected in the screenshot and their position and must not be used for any other tasks. The format of each extracted text and its position is {text, x, y}. The format of each detected icon and its position is {icon_name, x, y}\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {},\n",
    "            \"required\": []\n",
    "         }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d54f10-9d7c-4141-9a76-d5bf7440d61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tool_call(tool_name, tool_input):\n",
    "    \"\"\"\n",
    "    Process a tool call from Claude.\n",
    "    \n",
    "    Args:\n",
    "        tool_name (str): Name of the tool to execute.\n",
    "        tool_input (dict): Input parameters for the tool.\n",
    "    \n",
    "    Returns:\n",
    "        str: Result of the tool execution.\n",
    "    \"\"\"\n",
    "    if tool_name == \"open_pbi\":\n",
    "        return open_pbi()\n",
    "    elif tool_name == \"find_and_click_item\":\n",
    "        return find_and_click_item(tool_input[\"item_name\"])\n",
    "    elif tool_name == \"find_and_click_icon\":\n",
    "        return find_and_click_icon(tool_input[\"icon_name\"])\n",
    "    elif tool_name == \"perform_ocr\":\n",
    "        return perform_ocr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97627555-a51e-4073-abbd-f46eb6a5d444",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_reply(text):\n",
    "    \"\"\"\n",
    "    Extract reply content from Claude's response.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Response text containing reply tags.\n",
    "    \n",
    "    Returns:\n",
    "        str: Extracted reply content or None if not found.\n",
    "    \"\"\"\n",
    "    pattern = r'<reply>(.*?)</reply>'\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return None    \n",
    "    \n",
    "def chat():\n",
    "    \"\"\"\n",
    "    Main chat function to interact with the user and process Power BI automation tasks.\n",
    "    \"\"\"\n",
    "    system_prompt = \"\"\"\n",
    "    You are an agent designed to help users create Power BI dashboards. Be helpful and concise in your responses.\n",
    "    You have access to tools, but only use them when necessary. Only interact with Power BI â€” do not open or interact with any other apps, even if requested.\n",
    "    You can select, click, or double-click items (e.g., buttons, menus, files) using the find_and_click_item tool, but before doing so, first check if the item exists in the extracted text from the screenshot using the perform_ocr tool.\n",
    "    To click or double-click icons, you can use a dedicated tool by passing the icon name. Supported icon names include \"bar chart\",  \"column chart\", \"right arrow\", \"rectangle\", and \"checkmark\".\n",
    "    To choose a column from imported data, click the 'rectangle' icon next to the column name. Confirm the selection by verifying that the rectangle turns into a 'checkmark' icon.\n",
    "    Consider all the columns from imported data to generate any chart. Ensure that you find a 'checkmark' in front of each column.\n",
    "    Do not ask the user for permission to click or double-click items or icons.\n",
    "    Each time you respond:\n",
    "    First, think through your response.\n",
    "    Then, write the user-facing reply enclosed in <reply></reply> tags for easy parsing.\n",
    "    \"\"\"\n",
    "    user_message = input(\"\\nUser: \")\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_prompt,\n",
    "            \"cache_control\": {\"type\": \"default\"}  # This caches only the system prompt\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_message\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    messages = [{\"role\": \"user\", \"content\": user_message}]\n",
    "    while True:\n",
    "        if user_message == \"quit\":\n",
    "            break\n",
    "        #If the last message is from the assistant, \n",
    "        # get another input from the user\n",
    "        if messages[-1].get(\"role\") == \"assistant\":\n",
    "            user_message = input(\"\\nUser: \")\n",
    "            messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "\n",
    "        #Send a request to Claude\n",
    "        response = ANTHROPIC_CLIENT.messages.create(\n",
    "            model=MODEL_NAME,\n",
    "            system=system_prompt,\n",
    "            max_tokens=4096,\n",
    "            temperature = 0.0,\n",
    "            tools=tools,\n",
    "            messages=messages\n",
    "        )\n",
    "        # Update messages to include Claude's response\n",
    "        messages.append(\n",
    "            {\"role\": \"assistant\", \"content\": response.content}\n",
    "        )\n",
    "\n",
    "        \n",
    "        # Manage OCR tool calls to remove the old OCR content for token efficiency \n",
    "        perform_ocr_candidates = {}  # id -> block\n",
    "        perform_ocr_positions = []   # list of (index in messages, block)\n",
    "        \n",
    "        for i, msg in enumerate(messages):\n",
    "            if msg['role'] == 'assistant' and isinstance(msg['content'], list):\n",
    "                for block in msg['content']:\n",
    "                    if getattr(block, 'type', None) == 'tool_use' and getattr(block, 'name', None) == 'perform_ocr':\n",
    "                        perform_ocr_id = getattr(block, 'id', None)\n",
    "                        if perform_ocr_id:\n",
    "                            perform_ocr_candidates[perform_ocr_id] = block\n",
    "                            perform_ocr_positions.append((i, perform_ocr_id))\n",
    "        \n",
    "        # Determine which perform_ocr ID is the last one\n",
    "        last_perform_ocr_id = perform_ocr_positions[-1][1] if perform_ocr_positions else None\n",
    "        \n",
    "        # Identify perform_ocr tool_use IDs that actually received tool_result responses\n",
    "        used_perform_ocr_ids = set()\n",
    "        for msg in messages:\n",
    "            content = msg.get('content')\n",
    "            if isinstance(content, list):\n",
    "                for item in content:\n",
    "                    if isinstance(item, dict) and item.get('type') == 'tool_result':\n",
    "                        tool_use_id = item.get('tool_use_id')\n",
    "                        if tool_use_id in perform_ocr_candidates:\n",
    "                            used_perform_ocr_ids.add(tool_use_id)\n",
    "        \n",
    "        #  Remove perform_ocr tool_use blocks, except the last one (for token efficiency)\n",
    "        for msg in messages:\n",
    "            if msg['role'] == 'assistant' and isinstance(msg['content'], list):\n",
    "                msg['content'] = [\n",
    "                    block for block in msg['content']\n",
    "                    if not (\n",
    "                        getattr(block, 'type', None) == 'tool_use' and\n",
    "                        getattr(block, 'name', None) == 'perform_ocr' and\n",
    "                        getattr(block, 'id', None) in used_perform_ocr_ids and\n",
    "                        getattr(block, 'id', None) != last_perform_ocr_id\n",
    "                    )\n",
    "                ]\n",
    "        \n",
    "        # Remove user tool_result messages for all perform_ocrs *except* the last one (for token efficiency)\n",
    "        filtered_messages = []\n",
    "        for msg in messages:\n",
    "            content = msg.get('content')\n",
    "            if isinstance(content, list):\n",
    "                is_older_perform_ocr_tool_result = any(\n",
    "                    isinstance(item, dict) and\n",
    "                    item.get('type') == 'tool_result' and\n",
    "                    item.get('tool_use_id') in used_perform_ocr_ids and\n",
    "                    item.get('tool_use_id') != last_perform_ocr_id\n",
    "                    for item in content\n",
    "                )\n",
    "                if is_older_perform_ocr_tool_result:\n",
    "                    continue  # skip this message\n",
    "            filtered_messages.append(msg)\n",
    "        \n",
    "        # Final update\n",
    "        messages = filtered_messages\n",
    "\n",
    "        #If Claude stops because it wants to use a tool:\n",
    "        if response.stop_reason == \"tool_use\":\n",
    "            #Naive approach assumes only 1 tool is called at a time\n",
    "            tool_use = response.content[-1] \n",
    "            tool_name = tool_use.name\n",
    "            tool_input = tool_use.input\n",
    "            print(f\"=====Claude wants to use the {tool_name} tool=====\")\n",
    "\n",
    "\n",
    "            #Actually run the underlying tool functionality on our db\n",
    "            tool_result = process_tool_call(tool_name, tool_input)\n",
    "\n",
    "            #Add our tool_result message:\n",
    "            messages.append(\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"tool_result\",\n",
    "                            \"tool_use_id\": tool_use.id,\n",
    "                            \"content\": str(tool_result) }\n",
    "                    ],\n",
    "                },\n",
    "            )\n",
    "        else: \n",
    "            #If Claude does NOT want to use a tool, \n",
    "            #just print out the text reponse\n",
    "            model_reply = extract_reply(response.content[0].text)\n",
    "            print(\"\\nAcme Co Support: \" + f\"{model_reply}\" )\n",
    "\n",
    "        #print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cab41e-7b55-4682-a3f1-792ecb04ac1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start chatting with the agent\n",
    "chat()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
